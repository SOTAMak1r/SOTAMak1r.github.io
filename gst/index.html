<html lang="en-GB">
<head>
    <title>GST</title>
    <link rel="icon" href="./assets/figures/logo_new.png">

    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <!-- <title>Clarity: A Minimalist Website Template for AI Research</title> -->
    <meta name="description" content="We've presented Clarity, a minimalist and elegant website template for AI research.">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <meta name="robots" content="all">
    <meta content="en_EN" property="og:locale">
    <meta content="website" property="og:type">
    <meta content="https://shikun.io/projects/clarity" property="og:url">
    <meta content="Clarity" property="og:title">
    <meta content="Website Template for AI Research" property="og:description">

    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@your_twitter_id">
    <meta name="twitter:description" content="Clarity: A Minimalist Website Template for AI Research">
    <meta name="twitter:image:src" content="assets/figures/clarity.png">

    <link rel="stylesheet" type="text/css" media="all" href="assets/stylesheets/main_free.css" />
    <link rel="stylesheet" type="text/css" media="all" href="clarity/clarity.css" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/foundation.min.css">
    <link href="assets/fontawesome-free-6.6.0-web/css/all.min.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/img-comparison-slider@8/dist/styles.css"/>
    <script defer src="https://cdn.jsdelivr.net/npm/img-comparison-slider@8/dist/index.js"></script>
    <script src="assets/scripts/navbar.js"></script> <!-- Comment to remove table of content. -->
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            "HTML-CSS": {
              scale: 95,
              fonts: ["Gyre-Pagella"],
              imageFont: null,
              undefinedFamily: "'Arial Unicode MS', cmbright"
            },
            tex2jax: {
                inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                processEscapes: true
              }
          });
    </script>
    <script type="text/javascript"
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <style>
        .center {
          display: flex;
          justify-content: center;
          align-items: center;
          /* height: 100vh; */
        }
    </style>
</head>

<body>
    <!-- Define Menu -->
    <div id="header"></div>

    <!-- Title Page -->
    <!-- Dark Theme Example: Change the background colour dark and change the following div "blog-title" into "blog-title white". -->
    <div class="container blog" id="first-content" style="background-color: #e3f6f9;">
        <div class="blog-title">
            <div class="blog-intro">
                <div>
                    <!-- <h1 class="title">Clarity: A Minimalist Website Template for AI Research</h1> -->
                    <h1 class="title">
                        Where Am I and What Will I See : <br> 
                        An Auto-Regressive Model for Spatial Localization and View Prediction
                    </h1>
                    
                    <p class="author">
                        <a href="https://github.com/SOTAMak1r">Junyi Chen</a><sup>1,2</sup>,
                        <a href="https://dihuang.me/">Di Huang</a><sup>1†</sup>,
                        <a href="https://ywcmaike.github.io/">Weicai Ye</a><sup>1</sup>,
                        <a href="https://wlouyang.github.io/">Wanli Ouyang</a><sup>1</sup>,
                        <a href="https://tonghe90.github.io/">Tong He</a><sup>1</sup>
                        <br>
                        
                        <sup>1</sup>Shanghai AI Lab,
                        <sup>2</sup>Shanghai Jiao Tong University
                        <br>
                        <sup>†</sup>Corresponding Authors
                        <br>
                    </p>
                    
                    <p style="color: rgb(252, 164, 63)">
                        Accepted to ICLR 2025
                    </p>

                    <p>
                        <!-- Welcome to Clarity — an open-source, minimalist website template designed for presenting AI research. Originally developed as the foundation for my personal website, Clarity offers a modular, clean design that is easy to customise for simple, project-based website creation. With Clarity, you can effectively showcase your work, ensuring your research stands out in a visually appealing and professional manner.  -->
                        The spatial reasoning ability of humans allows individuals to effortlessly conceive novel views and corresponding viewpoint locations simultaneously within a given scene. 
                        Consequently, based on this finding, exploring the intrinsic connections between these two modalities is a vital step toward advancing spatial intelligence.

                    </p>
                    
                </div>
               
                <div class="info">
                    <a href="https://www.arxiv.org/abs/2410.18962" class="button icon" style="background-color: rgba(255, 255, 255, 0.5)">Paper</a>
                    <a href="https://github.com/SOTAMak1r/GST" class="button icon" style="background-color: rgba(255, 255, 255, 0.5)">Code</a>
                </div>
            </div>

            <div class="blog-cover">
                <img class="foreground" src="./assets/figures/logo_new.png">
                <img class="background" src="./assets/figures/logo_new.png">
            </div>
        </div>
    </div>


    <div class="container blog main first" id="blog-main">
        <h1>
            TL; DR
        </h1>
        <p class='text'>
            We introduce <b>G</b>enerative <b>S</b>patial <b>T</b>ransformer(GST), 
            the first model capable of concurrently performing both novel view synthesis and relative camera pose estimation within a unified framework. 
            Drawing inspiration from human spatial reasoning, we design GST to model the joint distribution of images and camera poses, 
            enabling it to effectively integrate the training objectives of both tasks. 
        </p>
    </div>


    <div class="container blog main gray">
        <h1>
            How it Works?
        </h1>
        <br>
        <div class="center">
            <iframe width="650" height="350" src="https://www.youtube.com/embed/pydiW0kexPE?si=BTWkMFXbNaynH3mV" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
        </div>
    </div>


    <div class="container blog main">
        <h1>
            Methods
        </h1>

        <p class="text">
            Previous methods have traditionally constructed unimodal target distributions for novel view synthesis and camera estimation tasks. 
            However, GST has introduced a joint distribution for both the image and the corresponding camera poses.
            This enables us to initiate from a single image while simultaneously sampling novel view images along with their corresponding perspectives.
        </p>

        <img src="./assets/figures/condition_distribution.png">

        <p class="text">
            Diverging from prior research, our focus lies in uncovering the inherent consistency between these two tasks rather than alternately training the two objectives during the training process.
            Our approach starts by tokenizing the image and camera spatial positions, merging two codebooks to ensure the model treats both modalities equally. 
            We then proceed to train a generative network to model the joint distribution of these components. 
            Our pipeline is shown in the figure below.
        </p>

        <img src="./assets/figures/pipeline.png">

    </div>



    <div class="container blog main">
        <h1>
            Samples
        </h1>

        <p class="text">
            For a given observational image, the GST initially sample multiple appropriate camera poses automatically ($p(c | o)$), 
            which are then employed as conditions to generate corresponding novel view images ($p(i | o, c)$).
        </p>
    </div>


    <div class="container blog max gray">
        <div class="slideshow">
            <div class="navigation">
                <!-- Using FontAwesome Pro -->
                <!-- <a class="button icon" id="prev_btn"><i class="fa-solid fa-left" ></i></a>
                <a class="button icon" id="next_btn"><i class="fa-solid fa-right"></i></a> -->
                <!-- Using FontAwesome Free -->
                <a class="button icon" id="prev_btn"><i class="fa-solid fa-arrow-left"></i></a>
                <a class="button icon" id="next_btn"><i class="fa-solid fa-arrow-right"></i></a>
            </div>
            <div class="slider">
                <div class="slider-item">
                    <!-- <video loop playsinline muted autoplay src="https://mardini-vidgen.github.io/clarity/videos/1.mp4"></video> -->
                    <img src="./assets/figures/sample_001.png">
                </div>
                <div class="slider-item">
                    <img src="./assets/figures/sample_002.png">
                </div>
                <div class="slider-item">
                    <img src="./assets/figures/sample_003.png">
                </div>
                <div class="slider-item">
                    <img src="./assets/figures/sample_004.png">
                </div>
                <div class="slider-item">
                    <img src="./assets/figures/sample_005.png">
                </div>
                <div class="slider-item">
                    <img src="./assets/figures/sample_006.png">
                </div>
                <div class="slider-item">
                    <img src="./assets/figures/sample_007.png">
                </div>
            </div>
        </div>
    </div>
    

    <div class="container blog main">
        <h1>
            Camera Pose Estimation
        </h1>

        <p class="text">
            We selected several highly challenging examples to test the spatial localization capabilities of GST.
            The selected image pairs include real-world images, 
            images of the same subject taken under different shooting conditions, 
            and images of the same object depicted under various artistic styles. 
            GST demonstrated outstanding performance across all these examples.
        </p>
    </div>


    <div class="container blog max gray">
        <div class="slideshow">
            <div class="navigation">
                <!-- Using FontAwesome Pro -->
                <!-- <a class="button icon" id="prev_btn"><i class="fa-solid fa-left" ></i></a>
                <a class="button icon" id="next_btn"><i class="fa-solid fa-right"></i></a> -->
                <!-- Using FontAwesome Free -->
                <a class="button icon" id="prev_btn"><i class="fa-solid fa-arrow-left"></i></a>
                <a class="button icon" id="next_btn"><i class="fa-solid fa-arrow-right"></i></a>
            </div>
            <div class="slider">
                <div class="slider-item">
                    <!-- <video loop playsinline muted autoplay src="https://mardini-vidgen.github.io/clarity/videos/1.mp4"></video> -->
                    <img src="./assets/figures/est_001.png">
                </div>
                <div class="slider-item">
                    <img src="./assets/figures/est_002.png">
                </div>
                <div class="slider-item">
                    <img src="./assets/figures/est_003.png">
                </div>
                <div class="slider-item">
                    <img src="./assets/figures/est_004.png">
                </div>
                <div class="slider-item">
                    <img src="./assets/figures/est_005.png">
                </div>
                <div class="slider-item">
                    <img src="./assets/figures/est_006.png">
                </div>
                <div class="slider-item">
                    <img src="./assets/figures/est_007.png">
                </div>
            </div>
        </div>
    </div>
    


    <div class="container blog main">
        <h1>
            Interesting Findings
        </h1>
        <p class="text">
            We capture a real-world object from various angles and positions, 
            allowing GST to sample valid camera distributions from $p(c|o)$ for each scenario. 
            For images captured from a top-down perspective (a), GST predominantly sampled cameras with a top-down viewpoint. 
            Similarly, for objects viewed from a frontal angle (b), GST preferentially sampled cameras with a frontal perspective. 
            Notably, in scenarios involving obstacles (c), GST  effectively avoided these obstructions and sampled reasonable camera positions. 
            These results, achieved without any manual intervention, further demonstrate GST's ability to accurately comprehend the spatial layout from observed images.
        </p>
    </div>
    <div class="container blog extra-large gray-linear">
        <img src="./assets/figures/traj.png">
    </div>

    <div class="container blog main">
        <h1>
            Citation
        </h1>
        <pre><code class="plaintext">@misc{chen2024iiseeautoregressive,
    title={Where Am I and What Will I See: An Auto-Regressive Model for Spatial Localization and View Prediction}, 
    author={Junyi Chen and Di Huang and Weicai Ye and Wanli Ouyang and Tong He},
    year={2024},
    eprint={2410.18962},
    archivePrefix={arXiv},
    primaryClass={cs.CV},
    url={https://arxiv.org/abs/2410.18962}, 
}
</code></pre>
    </div>



    <!-- Footer Page -->
    <footer>
        <div class="container">
            <p>
                This website is built on the <a href="https://shikun.io/projects/clarity">Clarity Template</a>, designed by <a href="https://shikun.io/">Shikun Liu</a>.
            </p>
        </div>    
    </footer>
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
    <script src="clarity/clarity.js"></script>    
    <script src="assets/scripts/main.js"></script>    
    </html>
</body>